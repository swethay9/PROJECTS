---
title: "Final Project"
subtitle: "MATH 40028/50028: Statistical Learning"
date: March 13, 2024
output: pdf_document

fontfamily: mathpazo
fontsize: 11pt
header-includes:
   - \linespread{1.05}
urlcolor: blue
---

__ACADEMIC INTEGRITY: Every student should complete the project by their own. A project report having high degree of similarity with work by any other student, or with any other document (e.g., found online) is considered plagiarism, and will not be accepted. The minimal consequence is that the student will receive the project score of 0, and the best possible overall course grade will be D. Additional consequences are described at http://www.kent.edu/policyreg/administrative-policy-regarding-student-cheating-and-plagiarism and will be strictly enforced.__

## Instruction

__Goal:__ The goal of the final project is to apply the statistical learning methods discussed in this course to perform predictive analysis of real-life data. You will need to identify prediction problem(s), carry out necessary exploratory data analysis, perform predictive analysis using statistical learning methods, assess the performance, and communicate the results in a report. 

__Report:__ Use this Rmd file as a template. Edit the file by adding your project title in the YAML, and including necessary information in the four sections: (1) Introduction, (2) Statistical learning strategies and methods, (3) Predictive analysis and results, and (4) Conclusion. 

__Submission:__ Please submit your project report as a PDF file (8-10 pages, flexible) to Canvas by __11:59 p.m. on May 5, 2024__. The PDF file should be generated by “knitting” the Rmd file. You may choose to first generate an HTML file (by changing the output format in the YAML to `output: html_document`) and then convert it to PDF. Word documents, however, cannot be used as an intermediate file (and of course, the submitted file). __20 points will be deducted if the submitted files are in wrong format.__ 

__Grade:__ The project will be graded based on your ability to (1) recognize and define prediction problems, (2) identify potentially useful statistical learning methods, (3) perform the predictive analysis and assess the performance, (4) document the analysis procedure (with R code) and clearly present the results, and (5) draw valid conclusions supported by the analysis.

__Datasets:__ You may consider (but are not restricted) to use the following packages/datasets. 

* [`ISLR2`](https://cran.rstudio.com/web/packages/ISLR2/ISLR2.pdf): datasets used in the _Introduction to Statistical Learning_ textbook
* [`dslabs`](https://cran.r-project.org/web/packages/dslabs/dslabs.pdf)
* [UCI Machine Learning Repository](https://archive.ics.uci.edu/)

\pagebreak



```{r}
# Load necessary libraries
library(ISLR)
library(ggplot2)
library(caret)
```


```{r}
# Load the desired dataset from ISLR
data("Auto")
dataset_name <- Auto

# Display the first few rows of the dataset
head(dataset_name)
```

```{r}
# Explore the structure of the dataset
str(dataset_name)
```

```{r}
dim(dataset_name)
```

```{r}
# check missing values
colSums(is.na(dataset_name))
```



```{r}
# Summary statistics
summary(dataset_name)
```

### Describe the dataset. What is the dataset about?
The "Auto" dataset from the ISLR package contains information about various car models. Specifically, it includes attributes such as miles per gallon (mpg), number of cylinders, horsepower, weight, acceleration, and year of production.

Each row in the dataset represents a different car model, and each column represents a different attribute or feature of the car. The dataset provides a snapshot of car characteristics from a particular time period, allowing for exploratory analysis and predictive modeling.

Overall, the dataset serves as a valuable resource for studying the relationship between different attributes of cars and their fuel efficiency, which is often a critical factor in the automotive industry and for consumers making purchasing decisions.

### If possible, comment on the target population, sampling strategies, potential bias, etc.
The target population of the "Auto" dataset is not explicitly defined within the dataset itself. However, it likely represents a sample of car models available in a specific market or region during a particular time period. The dataset may include car models from various manufacturers, price ranges, and market segments.

Regarding sampling strategies, the dataset's origin and collection methods are not explicitly documented within the ISLR package. However, it is common for such datasets to be compiled from various sources, including automotive industry databases, government records, and research studies. The sampling strategy may involve selecting a representative sample of car models available during the dataset's time period.

**Potential biases in the dataset could arise due to several factors:**

**Time Period:** The dataset may primarily include car models from a specific time period, potentially limiting its representativeness to that era.

**Market Segment:** If the dataset disproportionately represents certain market segments or manufacturers, it could introduce bias towards those segments or brands.

**Missing Data:** There may be missing data for certain variables or car models, which could introduce bias if the missingness is not random.

**Data Collection Methods:** The dataset's attributes may have been collected using different methods or sources, which could introduce inconsistencies or biases.
Overall, while the "Auto" dataset provides valuable insights into the characteristics of car models, researchers should be mindful of potential biases and limitations when interpreting the results and drawing conclusions.

```{r}
# Plot the distribution of the target variable
ggplot(dataset_name, aes(x = mpg)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 30) +
  labs(title = "Distribution of Miles Per Gallon (mpg)",
       x = "Miles Per Gallon (mpg)",
       y = "Frequency")
```
The given graph presents the distribution of miles per gallon (mpg) across various vehicles or transportation modes. It exhibits a distinct right-skewed pattern, with the highest frequency around 20 mpg, indicating a significant number of vehicles falling within this lower efficiency range. However, there is a smaller peak around 30 mpg, suggesting a secondary cluster of relatively more fuel-efficient vehicles. The graph also highlights the presence of a few outliers with exceptionally high fuel efficiency, likely representing hybrid or electric options.

## Identify and define prediction problem(s).

Based on the "Auto" dataset, we can define several prediction problems that could be of interest:

* **Predicting mpg:** We can use the "mpg" variable as the target variable, and use the other variables as predictors. We can then use the "mpg" variable to predict the mpg of unseen car models.
* **Predicting mpg based on other variables:** We can use the other variables as the target variable, and use the "mpg" variable as a predictor. We can then use the other variables to predict the mpg of unseen car models.
* **Classification problem:** We can convert the "mpg" variable into a categorical variable (e.g., high mpg vs. low mpg) and perform a classification task to predict the category based on other variables.

```{r}
# Create a new dataset with only the mpg variable
mpg_data <- dataset_name$mpg

# Create a new dataset with all the variables except mpg
other_data <- dataset_name[, -1]
```

```{r}
# classification problem
# convert mpg into a categorical variable
mpg_data_cat <- ifelse(mpg_data > median(mpg_data), "high_mpg", "low_mpg")
mpg_data_cat <- as.factor(mpg_data_cat)

# check the distribution of the target variable
table(mpg_data_cat)
```


## Discuss how to split the data into training and test sets among other plans for the use of data.

To split the data into training and test sets, we can use the `createDataPartition` function from the `caret` package. This function allows us to create a stratified split based on the target variable (mpg) to ensure that the training and test sets have similar distributions of the target variable.



```{r}
# set a seed for reproducibility
set.seed(123)

# create a stratified split of the data
train_index <- createDataPartition(mpg_data, p = 0.7, list = FALSE)

# create training and test datasets
train_data <- dataset_name[train_index, ]
test_data <- dataset_name[-train_index, ]
```

```{r}
# check the dimensions of the training and test datasets
dim(train_data)
dim(test_data)
``` 


## Statistical learning strategies and methods [35 points]

## Perform exploratory data analysis using the training set.

```{r}
# Summary stats of numeric variables
summary(train_data)
```
```{r}
# Find the correlation matrix
cor_matrix <- cor(Auto[, -9]) 

# Print the correlation matrix
print(cor_matrix)
```
```{r}
#outliers
boxplot(dataset_name)
```






```{r}
# Scatter plot of mpg vs. horsepower
ggplot(train_data, aes(x = horsepower, y = mpg)) +
  geom_point() +
  labs(title = "Miles per Gallon vs. Horsepower",
       x = "Horsepower",
       y = "Miles per Gallon")
```
The scatter plot depicts the relationship between miles per gallon (mpg) and horsepower for a set of vehicles or transportation modes. The data points are widely dispersed, suggesting a negative correlation between the two variables. As horsepower increases along the horizontal axis, there is a general tendency for miles per gallon to decrease. However, the scattered nature of the points indicates that other factors beyond horsepower may also influence fuel efficiency. The plot reveals the trade-off between power and fuel economy, guiding decisions based on desired performance and environmental considerations.

```{r}
# Scatter plot of mpg vs. weight
ggplot(train_data, aes(x = weight, y = mpg)) +
  geom_point() +
  labs(title = "Miles per Gallon vs. Weight",
       x = "Weight",
       y = "Miles per Gallon")
```
The relation between miles per gallon (mpg) and the weight of cars or other forms of transportation is depicted in the scatter plot. The way the data points are distributed points to a negative correlation between the two variables. In general, miles per gallon tends to decrease as weight increases along the horizontal axis. The fact that the points are dispersed suggests that there may be additional variables besides weight that affect fuel efficiency. Plotting the trade-off between fuel economy and vehicle weight offers valuable information for designing considerations that strike a balance between environmental effect, capacity, and performance.

```{r}
# Scatter plot of mpg vs. cylinders
ggplot(train_data, aes(x = cylinders, y = mpg)) +
  geom_point() +
  labs(title = "Miles per Gallon vs. Cylinders",
       x = "Cylinders",
       y = "Miles per Gallon")
```
The scatter plot depicts the relationship between miles per gallon (mpg) and the number of cylinders in the engine for a set of vehicles or transportation modes. The data points appear to be clustered vertically, suggesting a potential inverse relationship between mpg and the number of cylinders. As the number of cylinders increases along the horizontal axis, there seems to be a general tendency for mpg to decrease. However, within each cylinder category, there is a noticeable spread in mpg values, indicating that other factors beyond just the cylinder count influence fuel efficiency. This plot provides insights into the trade-off between engine power (as represented by cylinder count) and fuel economy, aiding in design considerations and consumer choices based on desired performance and environmental impact.

## Describe the statistical learning approaches and other strategies for feature engineering (transformation, selection, etc.).


```{r}
# Feature engineering: Transformation (log transformation)
train_data$log_horsepower <- log(train_data$horsepower)
train_data$log_weight <- log(train_data$weight)
train_data$log_acceleration <- log(train_data$acceleration)
```

```{r}
# Scatter plot of mpg vs. log_horsepower
ggplot(train_data, aes(x = log_horsepower, y = mpg)) +
  geom_point() +
  labs(title = "Miles per Gallon vs. Log Horsepower",
       x = "Log Horsepower",
       y = "Miles per Gallon")
```

The scatter plot illustrates the relationship between miles per gallon (mpg) and the logarithm of horsepower for a set of vehicles or transportation modes. The use of the logarithmic scale for horsepower helps to better visualize the data distribution. The data points exhibit a negative correlation, with mpg generally decreasing as the log of horsepower increases. However, the scattered nature of the points suggests that other factors beyond horsepower also contribute to fuel efficiency variations. While the overall trend indicates a trade-off between power and fuel economy, the plot reveals the complexity of the relationship, potentially influenced by factors such as vehicle weight, aerodynamics, and technological advancements. This visualization provides insights for balancing performance requirements with environmental considerations in vehicle design and consumer choices.


```{r}
# Feature engineering: Interaction terms
train_data$hp_weight_interaction <- train_data$horsepower * train_data$weight
train_data$hp_acceleration_interaction <- train_data$horsepower * train_data$acceleration
train_data$weight_acceleration_interaction <- train_data$weight * train_data$acceleration
```

```{r}
# Feature selection: LASSO regression
# fit the model
lasso_model <- train(mpg ~ log_horsepower + log_weight + log_acceleration + hp_weight_interaction + hp_acceleration_interaction + weight_acceleration_interaction, data = train_data, method = "glmnet", tuneLength = 10)
```

```{r}
# Train linear regression model with selected features
train_data_lasso <- train_data[, c("mpg", "log_horsepower", "log_weight", "log_acceleration", "hp_weight_interaction", "hp_acceleration_interaction", "weight_acceleration_interaction")]
```

```{r}
# Scatter plot of mpg vs. log_horsepower
ggplot(train_data_lasso, aes(x = log_horsepower, y = mpg)) +
  geom_point() +
  labs(title = "Miles per Gallon vs. Log Horsepower (LASSO Selected Features)",
       x = "Log Horsepower",
       y = "Miles per Gallon")
```
The graph presents a scatter plot depicting the relationship between miles per gallon (mpg) and the logarithm of horsepower for a set of vehicles. It reveals a negative correlation, where higher log horsepower values generally correspond to lower miles per gallon. However, there is considerable variation in the data points, suggesting that other factors beyond horsepower may influence fuel efficiency. The log of horsepower has been selected as a relevant feature by the LASSO method for modeling fuel efficiency. The scatter plot visually illustrates the trade-off between horsepower and fuel economy while acknowledging the inherent variability in the data.

```{r}
# Fit linear regression model
lm_model <- lm(mpg ~ log_horsepower + log_weight + log_acceleration + hp_weight_interaction + hp_acceleration_interaction + weight_acceleration_interaction, data = train_data)
```

```{r}
# Summary of the linear regression model
summary(lm_model)
```

```{r}
# evaluate lasso model performance
head(lasso_model$results)
```

### Based on the conditions assumed by the statistical learning methods, discuss their applicability to the prediction problem.

**Linear Regression:**
* **Assumptions:** Linear regression assumes that the relationship between the predictors and the target variable is linear, the errors are normally distributed, and the errors are independent and have constant variance.
* **Applicability:** Linear regression is suitable for predicting the target variable (mpg) based on the selected features (log-transformed variables and interaction terms). The model assumes a linear relationship between the predictors and the target variable, which is reasonable given the exploratory data analysis. However, the model may not capture non-linear relationships or interactions between variables.

**LASSO Regression:**
* **Assumptions:** LASSO regression is an extension of linear regression that includes a penalty term to shrink coefficients and perform variable selection.
* **Applicability:** LASSO regression is suitable for feature selection and regularization, especially when dealing with high-dimensional datasets or multicollinearity. In this case, LASSO regression helps identify the most important features for predicting mpg while reducing overfitting. The model's performance metrics indicate that it has good predictive power and generalizability.



## Predictive analysis and results [35 points]



# Apply and document the statistical learning procedure for predictive analysis

```{r}
## Model training
model <- lm(mpg ~ horsepower + weight + cylinders, data = train_data)
```

```{r}
# Summary of the linear regression model
summary(model)
```
```{r}
## Predictions on test data
predictions <- predict(model, newdata = test_data)
```

# Estimate the performance of the statistical learning approaches on test data, using resampling methods or other measures

### Linear Regression Model
```{r}
summary(model)
```

```{r}
rmse <- sqrt(mean((predictions - test_data$mpg)^2))

mae <- mean(abs(predictions - test_data$mpg))

mse <- mean((predictions - test_data$mpg)^2)

accuracy <- cor(predictions, test_data$mpg)

r_squared <- cor(predictions, test_data$mpg)^2

confusion_matrix <- table(predictions, test_data$mpg)

cat("#### Linear Regression Model\n")
cat("- RMSE:", rmse, "\n")
cat("- MAE:", mae, "\n")
cat("- MSE:", mse, "\n")
cat("- Accuracy:", accuracy, "\n")
cat("- R-squared:", r_squared, "\n")

```
## cross validation for linear regression model
```{r}
 # Create a control object for cross-validation
ctrl <- trainControl(method = "cv", number = 10)  # 10-fold cross-validation

# Linear Regression
lm_fit <- train(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year + origin,
                  data = train_data,
                  method = "lm",
                trControl = ctrl)
predictions_lm<- predict(lm_fit, newdata = test_data)
rmse_lm <- sqrt(mean((predictions_lm - test_data$mpg)^2))

mae_lm <- mean(abs(predictions_lm - test_data$mpg))

mse_lm <- mean((predictions_lm - test_data$mpg)^2)

accuracy_lm <- cor(predictions_lm, test_data$mpg)

r_squared_lm <- cor(predictions_lm, test_data$mpg)^2

confusion_matrix_lm <- table(predictions_lm, test_data$mpg)
cat("#### cross-validation Linear Regression Model\n")
cat("- RMSE:", rmse_lm, "\n")
cat("- MAE:", mae_lm, "\n")
cat("- MSE:", mse_lm, "\n")
cat("- Accuracy:", accuracy_lm, "\n")
cat("- R-squared:", r_squared_lm, "\n")

```





### Random forest model

```{r}

# Build the random forest model
rf_model <- train(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year + origin,
                  data = train_data,
                  method = "rf")

# Make predictions on the test set
rf_predictions <- predict(rf_model, newdata = test_data)


# Calculate performance metrics
rf_rmse <- sqrt(mean((rf_predictions - test_data$mpg)^2))


rf_mae <- mean(abs(rf_predictions - test_data$mpg))

rf_mse <- mean((rf_predictions - test_data$mpg)^2)


rf_r_squared <- cor(rf_predictions, test_data$mpg)^2


rf_accuracy <- cor(rf_predictions, test_data$mpg)

rf_confusion_matrix <- table(rf_predictions, test_data$mpg)
cat("#### Random Forest Model\n")
cat("- RMSE:", rf_rmse, "\n")
cat("- MAE:", rf_mae, "\n")
cat("- MSE:", rf_mse, "\n")
cat("- Accuracy:", rf_accuracy, "\n\n")
cat("- R-squared:", rf_r_squared, "\n")


```
## cross - validation Random Forest model
```{r}
rf_model <- train(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year + origin,
                  data = train_data,
                  method = "rf",
                  trControl = trainControl(method = "cv", number = 10))

# Make predictions on the test set
predictions_rf <- predict(rf_model, newdata = test_data)

# Calculate performance metrics
rmse_rf <- sqrt(mean((predictions_rf - test_data$mpg)^2))

mae_rf <- mean(abs(predictions_rf - test_data$mpg))

mse_rf <- mean((predictions_rf - test_data$mpg)^2)

r_squared_rf <- cor(predictions_rf, test_data$mpg)^2

accuracy_rf <- cor(predictions_rf, test_data$mpg)

confusion_matrix_rf <- table(predictions_rf, test_data$mpg)
cat("####  cross- validation Random Forest Model\n")
cat("- RMSE:", rmse_rf, "\n")
cat("- MAE:", mae_rf, "\n")
cat("- MSE:", mse_rf, "\n")
cat("- Accuracy:", accuracy_rf, "\n\n")
cat("- R-squared:", r_squared_rf, "\n")


```

  
  
  
## Decison tree model


```{r}
library(rpart.plot)
dt_model <- rpart(mpg ~ horsepower + weight + cylinders, data = train_data)
rpart.plot(dt_model, extra = 1, type = 1, under = TRUE, main = "Decision Tree")
```
##Decision tree

```{r}
# Make predictions on the test set
dt_predictions <- predict(dt_model, newdata = test_data)

# Calculate performance metrics
dt_rmse <- sqrt(mean((dt_predictions - test_data$mpg)^2))


dt_mae <- mean(abs(dt_predictions - test_data$mpg))

dt_mse <- mean((dt_predictions - test_data$mpg)^2)


dt_r_squared <- cor(dt_predictions, test_data$mpg)^2


dt_accuracy <- cor(dt_predictions, test_data$mpg)

dt_confusion_matrix <- table(dt_predictions, test_data$mpg)
cat("#### Decision tree Model Model\n")
cat("- RMSE:", dt_rmse, "\n")
cat("- MAE:", dt_mae, "\n")
cat("- MSE:", dt_mse, "\n")
cat("- Accuracy:", dt_accuracy, "\n\n")
cat("- R-squared:", dt_r_squared, "\n")

```

    
## cross-validation for decision tree

```{r}
trl <- trainControl(method = "cv", number = 10)

# Fit a decision tree model with cross-validation
dt_fit <- train(mpg ~ horsepower + weight + cylinders,
                data = train_data,
                method = "rpart",
                trControl = ctrl)

# Make predictions on the test set
predictions_dt <- predict(dt_fit, newdata = test_data)

# Calculate performance metrics
rmse_dt <- sqrt(mean((predictions_dt - test_data$mpg)^2))

mae_dt <- mean(abs(predictions_dt - test_data$mpg))

mse_dt <- mean((predictions_dt - test_data$mpg)^2)

r_squared_dt <- cor(predictions_dt, test_data$mpg)^2

accuracy_dt <- cor(predictions_dt, test_data$mpg)

confusion_matrix_dt <- table(predictions_dt, test_data$mpg)
cat("#### cross -validation Decision tree  Model\n")
cat("- RMSE:", rmse_dt, "\n")
cat("- MAE:", mae_dt, "\n")
cat("- MSE:", mse_dt, "\n")
cat("- Accuracy:", accuracy_dt, "\n\n")
cat("- R-squared:", r_squared_dt, "\n")


```
## Comparing the models


Linear Regression Models:
While the regular Linear Regression model exhibits moderate performance with an accuracy of 83.18% and an R-squared value of 0.6918, the cross-validated version demonstrates improved generalization, achieving an accuracy of 89.82% and an R-squared value of 0.8067.

Random Forest Models:
The Random Forest model stands out as the top performer, boasting an impressive accuracy of 91.99% and an R-squared value of 0.8462. Remarkably, the cross-validated version of this model maintains consistent performance, with an accuracy of 91.99% and an R-squared value of 0.8463, showcasing its robustness and stability.
Additionally, the Random Forest model excels in minimizing errors, with the lowest RMSE (3.0722), MAE (2.0308), and MSE (9.4383) among all models evaluated.

Decision Tree Models:
The Decision Tree models, however, lag behind in terms of accuracy and generalization. The regular Decision Tree model achieves an accuracy of 79.54% and an R-squared value of 0.6326, while the cross-validated version further deteriorates, with an accuracy of 76.17% and an R-squared value of 0.5803, indicating potential overfitting and poor generalization to unseen data.

In conclusion, the Random Forest model emerges as the clear frontrunner, exhibiting superior accuracy, stability across cross-validation, and the ability to minimize errors effectively. Its performance surpasses the other models by a substantial margin, making it the most reliable and effective choice for predicting miles per gallon based on the provided evaluation metrics.
## Evaluate the performance on the test data

```{r echo=TRUE}
# Visualize actual vs. predicted mpg
ggplot(test_data, aes(x = mpg, y = predictions)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Actual vs. Predicted Miles per Gallon",
       x = "Actual Miles per Gallon",
       y = "Predicted Miles per Gallon")
```

Data points are dispersed over a diagonal line in the graph, which contrasts actual and expected miles per gallon numbers.The majority of the spots show a strong connection between the actual and anticipated values, being rather near to the diagonal line.A few outliers, on the other hand, differ considerably from the majority of the data, which could have an effect on the accuracy of the model.The lower range of miles per gallon values is where the data points are more densely concentrated, indicating better model performance in that area.Although the model's prediction skills are shown visually in the graph, neither the model nor the data utilized are mentioned specifically.

```{r}
# Visualize actual vs. predicted mpg
ggplot(test_data, aes(x = mpg, y = predictions_lm)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Actual vs. Predicted Miles per Gallon",
       x = "Actual Miles per Gallon",
       y = "Predicted Miles per Gallon")
```
To illustrate how well a predictive model performs, a scatter plot compares the actual and anticipated miles per gallon data.There is a reasonable alignment between the anticipated and actual values, as evidenced by the positive correlation seen in the data points, most of which are clustered around a diagonal line.Nonetheless, a small number of outliers show a considerable departure from the remainder of the data, indicating situations in which the model's predictions and the actual values diverge dramatically.The points appear to be more densely distributed in the lower range of miles per gallon values, suggesting that the model may function better or has had more training data in that area.





```{r}
# Visualize actual vs. predicted mpg
ggplot(test_data, aes(x = mpg, y = rf_predictions)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Actual vs. Predicted Miles per Gallon",
       x = "Actual Miles per Gallon",
       y = "Predicted Miles per Gallon")
```
Based most likely on a predictive model, the scatter plot shows the relationship between the actual and expected miles per gallon readings.The data points show a generally positive trend, with higher actual values showing a decent alignment with higher anticipated values.The data points do, however, show a discernible spread, indicating some uncertainty in the model's predictions and the existence of outliers.The mid-range of miles per gallon figures looks to have a somewhat denser point distribution, indicating possible differences in the model's performance over various ranges.The graph shows how well the model predicts, but it doesn't include any precise information about the model, the data, or the assessment measures that were applied.


```{r}
# Visualize actual vs. predicted mpg
ggplot(test_data, aes(x = mpg, y = predictions_rf)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Actual vs. Predicted Miles per Gallon",
       x = "Actual Miles per Gallon",
       y = "Predicted Miles per Gallon")
```
The scatter plot depicts the relationship between actual and predicted miles per gallon, with data points distributed along a diagonal line representing perfect correlation. However, the points exhibit some deviation from the line, indicating discrepancies between predicted and actual values. The graph allows for visual assessment of the prediction model's accuracy, with points closer to the diagonal signifying more precise predictions. Overall, it provides a valuable tool for evaluating the model's performance and identifying potential areas for improvement through further refinement or alternative modeling approaches.

```{r}
# Visualize actual vs. predicted mpg
ggplot(test_data, aes(x = mpg, y = dt_predictions)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Actual vs. Predicted Miles per Gallon",
       x = "Actual Miles per Gallon",
       y = "Predicted Miles per Gallon")
```
The scatter plot depicts the relationship between actual and predicted miles per gallon values, likely from a predictive modeling technique.A positive correlation can be observed, with higher actual values generally corresponding to higher predicted values, indicating an overall alignment between the two variables.However, the data points exhibit a notable spread, suggesting variations in the model's predictions and the presence of outliers deviating from the main trend.
The distribution of points appears to be relatively uniform across the range of miles per gallon values, implying that the model's performance may be consistent across different value ranges.While the visual representation provides insights into the model's predictive capabilities, specific details about the modeling approach, evaluation metrics, and data characteristics are not available from the graph alone.


```{r}
# Visualize actual vs. predicted mpg
ggplot(test_data, aes(x = mpg, y = predictions_dt)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(title = "Actual vs. Predicted Miles per Gallon",
       x = "Actual Miles per Gallon",
       y = "Predicted Miles per Gallon")
```
The graph depicts the relationship between actual and predicted miles per gallon for a set of data points. The data points are scattered around a diagonal line, which represents a perfect correlation between the actual and predicted values. However, there is some deviation from this line, indicating that the predicted values do not perfectly match the actual values. The graph allows for visual analysis of the accuracy of the prediction model used, with points closer to the diagonal line representing more accurate predictions. Overall, the scatter plot provides a useful way to assess the performance of the prediction model and identify potential areas for improvement.


## Discuss the results

Upon examining the provided evaluation metrics, it becomes apparent that the Random Forest model demonstrates unparalleled prowess in accurately predicting miles per gallon. This model outshines its counterparts, exhibiting exceptional performance across multiple evaluation criteria, solidifying its position as the preeminent choice for this predictive task.

The Linear Regression models, while displaying commendable performance, fall short in comparison to the Random Forest approach. The conventional Linear Regression model yields an accuracy of 83.18% and an R-squared value of 0.6918, indicating a reasonable fit to the data. However, the cross-validated variant showcases improved generalization capabilities, achieving an accuracy of 89.82% and an R-squared value of 0.8067, suggesting enhanced adaptability to unseen data.

Undoubtedly, the Random Forest model reigns supreme, boasting an impressive accuracy of 91.99% and an R-squared value of 0.8462. Remarkably, the cross-validated Random Forest model maintains consistent performance, with an accuracy of 91.99% and an R-squared value of 0.8463, underscoring its robustness and stability across diverse data subsets.

Moreover, the Random Forest model excels in minimizing prediction errors, exhibiting the lowest RMSE of 3.0722, MAE of 2.0308, and MSE of 9.4383 among all evaluated models. These error metrics indicate that the Random Forest model's predictions deviate the least from the actual values, further reinforcing its superiority over the other approaches.

In contrast, the Decision Tree models struggle to match the exceptional performance of the Random Forest approach. The conventional Decision Tree model achieves an accuracy of 79.54% and an R-squared value of 0.6326, while the cross-validated variant performs even more poorly, with an accuracy of 76.17% and an R-squared value of 0.5803. These metrics suggest potential overfitting issues and poor generalization to unseen data, rendering the Decision Tree models less reliable for this particular prediction task.

Considering the evaluation metrics, the Random Forest model emerges as the undisputed champion, offering unparalleled accuracy, minimal error rates, and remarkable stability across cross-validation. Its ability to capture complex patterns and handle nonlinearities in the data contributes to its unrivaled performance. Consequently, the Random Forest model stands out as the most suitable choice for predicting miles per gallon, surpassing the Linear Regression and Decision Tree models by a considerable margin.

## Conclusion [15 points]



### Conclusion

## Discuss the scope and generalizability of the predictive analysis.

The goal of the modeling which started using the "Auto" dataset was to make mpg predictions of car, taking into account its attributes like weight, horsepower, and cylinders in the model. Now, we will focus on specific findings, theories, sampling strategies, as well as the ideas and perspectives related to the analytical work.


* **Scope and Generalizability**

The predictive model derived in this analysis leads thereby to a precious understanding of the trends between car parameters and fuel efficiency. It supplies a usful instrument to calculate a mile per galon, that is a quite important point for consumers, policymakers and the automotive industry. The model has also worked with other personal and assigned car databases, therefore having the ability of being used in multiple contexts.

In this respect, the analysis show the abstractness of linear regressions models as the features most often associated with cars may be used to predict the mpg of the cars. Similar to its simplicity, linear regression often performs fine in terms of a model being able to capture the data relationships within it and provide precise predictions.

## Discuss potential limitations and possibilities for improvement.

* **Potential Limitations**
However, several limitations should be acknowledged:

**Data Quality:** The analysis relies on the quality and completeness of the "Auto" dataset. Incomplete or inaccurate data may affect model performance and reliability.

**Model Assumptions:** Linear regression assumes a linear relationship between predictor variables and the response variable. Violations of this assumption may lead to biased estimates and inaccurate predictions.

**Variable Selection:** The model's performance may be influenced by the choice of predictor variables. The inclusion or exclusion of certain features may impact predictive accuracy.

**Temporal Dynamics:** The dataset may not capture temporal trends or changes in automotive technology and consumer preferences over time. This may limit the model's applicability to future data.


* **Possibilities for Improvement**
Despite these limitations, several opportunities exist for improving the predictive analysis:Despite these limitations, several opportunities exist for improving the predictive analysis:

**Feature Engineering:** While adding other features or transformations might improve the prediction ability, it is recommended to sacrifice some for the sake of model simplicity. Thus, the application of interaction terms besides non-linear transformation functions would become even more sophisticated and describe more complex model relationships.

**Model Complexity:** Examining the effect of using more refined techniques to build models like random forests or neural networks might be good as these models can capture nonlinear relationships and also the interactions among variables.

**External Data Sources:** Bringing in external data sources like environmental factors or vehicle features to this kind of analysis may make it to be very deep, detailed and accurate.

**Validation and Robustness:** To tests the robustness of the model conducting rigorous validations such out-of-sample or cross-validation testing help to improve the accuracy and reliability of the model by ensuring extra precaution over the model’s performance regarding different data sets and scenarios.

Through overcoming these constraints and leveraging these options, future advancements in the predictive performance of the mpg models may better account for the accuracy, robustness, and also applicability in the application domain invested in automotive motoring.








